{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/10000 hypothesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
      "Epoch  100/10000 hypothesis: tensor([152.7691, 183.6985, 180.9591, 197.0627, 140.1336]) Cost: 1.563634\n",
      "Epoch  200/10000 hypothesis: tensor([152.7273, 183.7273, 180.9465, 197.0517, 140.1731]) Cost: 1.497608\n",
      "Epoch  300/10000 hypothesis: tensor([152.6866, 183.7554, 180.9343, 197.0409, 140.2116]) Cost: 1.435026\n",
      "Epoch  400/10000 hypothesis: tensor([152.6470, 183.7827, 180.9224, 197.0304, 140.2491]) Cost: 1.375730\n",
      "Epoch  500/10000 hypothesis: tensor([152.6085, 183.8093, 180.9108, 197.0201, 140.2856]) Cost: 1.319511\n",
      "Epoch  600/10000 hypothesis: tensor([152.5711, 183.8352, 180.8996, 197.0101, 140.3211]) Cost: 1.266222\n",
      "Epoch  700/10000 hypothesis: tensor([152.5346, 183.8604, 180.8887, 197.0003, 140.3558]) Cost: 1.215696\n",
      "Epoch  800/10000 hypothesis: tensor([152.4992, 183.8849, 180.8781, 196.9908, 140.3895]) Cost: 1.167818\n",
      "Epoch  900/10000 hypothesis: tensor([152.4647, 183.9087, 180.8677, 196.9814, 140.4223]) Cost: 1.122429\n",
      "Epoch 1000/10000 hypothesis: tensor([152.4312, 183.9319, 180.8577, 196.9723, 140.4543]) Cost: 1.079378\n",
      "Epoch 1100/10000 hypothesis: tensor([152.3986, 183.9544, 180.8479, 196.9633, 140.4855]) Cost: 1.038584\n",
      "Epoch 1200/10000 hypothesis: tensor([152.3669, 183.9763, 180.8385, 196.9546, 140.5159]) Cost: 0.999894\n",
      "Epoch 1300/10000 hypothesis: tensor([152.3360, 183.9977, 180.8293, 196.9461, 140.5454]) Cost: 0.963217\n",
      "Epoch 1400/10000 hypothesis: tensor([152.3060, 184.0184, 180.8203, 196.9377, 140.5743]) Cost: 0.928421\n",
      "Epoch 1500/10000 hypothesis: tensor([152.2769, 184.0386, 180.8116, 196.9296, 140.6023]) Cost: 0.895453\n",
      "Epoch 1600/10000 hypothesis: tensor([152.2485, 184.0582, 180.8031, 196.9216, 140.6297]) Cost: 0.864161\n",
      "Epoch 1700/10000 hypothesis: tensor([152.2209, 184.0773, 180.7949, 196.9138, 140.6563]) Cost: 0.834503\n",
      "Epoch 1800/10000 hypothesis: tensor([152.1940, 184.0959, 180.7869, 196.9062, 140.6823]) Cost: 0.806375\n",
      "Epoch 1900/10000 hypothesis: tensor([152.1679, 184.1140, 180.7792, 196.8988, 140.7076]) Cost: 0.779696\n",
      "Epoch 2000/10000 hypothesis: tensor([152.1425, 184.1316, 180.7716, 196.8915, 140.7322]) Cost: 0.754389\n",
      "Epoch 2100/10000 hypothesis: tensor([152.1179, 184.1487, 180.7643, 196.8843, 140.7562]) Cost: 0.730373\n",
      "Epoch 2200/10000 hypothesis: tensor([152.0939, 184.1654, 180.7572, 196.8774, 140.7795]) Cost: 0.707607\n",
      "Epoch 2300/10000 hypothesis: tensor([152.0705, 184.1815, 180.7502, 196.8705, 140.8023]) Cost: 0.685989\n",
      "Epoch 2400/10000 hypothesis: tensor([152.0478, 184.1973, 180.7435, 196.8639, 140.8245]) Cost: 0.665497\n",
      "Epoch 2500/10000 hypothesis: tensor([152.0258, 184.2126, 180.7370, 196.8573, 140.8461]) Cost: 0.646035\n",
      "Epoch 2600/10000 hypothesis: tensor([152.0043, 184.2275, 180.7307, 196.8509, 140.8672]) Cost: 0.627585\n",
      "Epoch 2700/10000 hypothesis: tensor([151.9834, 184.2420, 180.7245, 196.8447, 140.8878]) Cost: 0.610050\n",
      "Epoch 2800/10000 hypothesis: tensor([151.9631, 184.2561, 180.7185, 196.8385, 140.9078]) Cost: 0.593426\n",
      "Epoch 2900/10000 hypothesis: tensor([151.9434, 184.2698, 180.7127, 196.8326, 140.9273]) Cost: 0.577643\n",
      "Epoch 3000/10000 hypothesis: tensor([151.9242, 184.2831, 180.7070, 196.8267, 140.9463]) Cost: 0.562648\n",
      "Epoch 3100/10000 hypothesis: tensor([151.9056, 184.2961, 180.7016, 196.8209, 140.9648]) Cost: 0.548429\n",
      "Epoch 3200/10000 hypothesis: tensor([151.8875, 184.3087, 180.6962, 196.8153, 140.9828]) Cost: 0.534923\n",
      "Epoch 3300/10000 hypothesis: tensor([151.8698, 184.3209, 180.6911, 196.8098, 141.0004]) Cost: 0.522093\n",
      "Epoch 3400/10000 hypothesis: tensor([151.8527, 184.3329, 180.6860, 196.8044, 141.0176]) Cost: 0.509904\n",
      "Epoch 3500/10000 hypothesis: tensor([151.8361, 184.3445, 180.6811, 196.7991, 141.0343]) Cost: 0.498317\n",
      "Epoch 3600/10000 hypothesis: tensor([151.8199, 184.3557, 180.6764, 196.7939, 141.0506]) Cost: 0.487341\n",
      "Epoch 3700/10000 hypothesis: tensor([151.8041, 184.3667, 180.6718, 196.7888, 141.0665]) Cost: 0.476888\n",
      "Epoch 3800/10000 hypothesis: tensor([151.7888, 184.3774, 180.6673, 196.7838, 141.0820]) Cost: 0.466961\n",
      "Epoch 3900/10000 hypothesis: tensor([151.7740, 184.3877, 180.6630, 196.7789, 141.0970]) Cost: 0.457528\n",
      "Epoch 4000/10000 hypothesis: tensor([151.7595, 184.3978, 180.6588, 196.7742, 141.1118]) Cost: 0.448554\n",
      "Epoch 4100/10000 hypothesis: tensor([151.7455, 184.4076, 180.6547, 196.7694, 141.1261]) Cost: 0.440032\n",
      "Epoch 4200/10000 hypothesis: tensor([151.7318, 184.4172, 180.6508, 196.7649, 141.1401]) Cost: 0.431924\n",
      "Epoch 4300/10000 hypothesis: tensor([151.7185, 184.4264, 180.6469, 196.7603, 141.1537]) Cost: 0.424216\n",
      "Epoch 4400/10000 hypothesis: tensor([151.7057, 184.4355, 180.6432, 196.7559, 141.1670]) Cost: 0.416880\n",
      "Epoch 4500/10000 hypothesis: tensor([151.6931, 184.4442, 180.6396, 196.7516, 141.1799]) Cost: 0.409898\n",
      "Epoch 4600/10000 hypothesis: tensor([151.6810, 184.4527, 180.6361, 196.7473, 141.1926]) Cost: 0.403257\n",
      "Epoch 4700/10000 hypothesis: tensor([151.6691, 184.4610, 180.6326, 196.7431, 141.2049]) Cost: 0.396937\n",
      "Epoch 4800/10000 hypothesis: tensor([151.6576, 184.4691, 180.6293, 196.7390, 141.2169]) Cost: 0.390926\n",
      "Epoch 4900/10000 hypothesis: tensor([151.6465, 184.4769, 180.6262, 196.7350, 141.2286]) Cost: 0.385192\n",
      "Epoch 5000/10000 hypothesis: tensor([151.6356, 184.4845, 180.6230, 196.7311, 141.2401]) Cost: 0.379738\n",
      "Epoch 5100/10000 hypothesis: tensor([151.6251, 184.4919, 180.6200, 196.7272, 141.2512]) Cost: 0.374542\n",
      "Epoch 5200/10000 hypothesis: tensor([151.6148, 184.4991, 180.6171, 196.7234, 141.2621]) Cost: 0.369586\n",
      "Epoch 5300/10000 hypothesis: tensor([151.6049, 184.5061, 180.6143, 196.7197, 141.2727]) Cost: 0.364854\n",
      "Epoch 5400/10000 hypothesis: tensor([151.5952, 184.5129, 180.6115, 196.7160, 141.2830]) Cost: 0.360357\n",
      "Epoch 5500/10000 hypothesis: tensor([151.5858, 184.5195, 180.6088, 196.7124, 141.2931]) Cost: 0.356064\n",
      "Epoch 5600/10000 hypothesis: tensor([151.5767, 184.5259, 180.6063, 196.7088, 141.3029]) Cost: 0.351970\n",
      "Epoch 5700/10000 hypothesis: tensor([151.5679, 184.5322, 180.6038, 196.7054, 141.3126]) Cost: 0.348059\n",
      "Epoch 5800/10000 hypothesis: tensor([151.5592, 184.5382, 180.6013, 196.7019, 141.3219]) Cost: 0.344323\n",
      "Epoch 5900/10000 hypothesis: tensor([151.5509, 184.5441, 180.5990, 196.6986, 141.3311]) Cost: 0.340758\n",
      "Epoch 6000/10000 hypothesis: tensor([151.5428, 184.5498, 180.5967, 196.6953, 141.3400]) Cost: 0.337356\n",
      "Epoch 6100/10000 hypothesis: tensor([151.5349, 184.5554, 180.5945, 196.6920, 141.3487]) Cost: 0.334104\n",
      "Epoch 6200/10000 hypothesis: tensor([151.5273, 184.5608, 180.5924, 196.6888, 141.3572]) Cost: 0.330994\n",
      "Epoch 6300/10000 hypothesis: tensor([151.5199, 184.5660, 180.5903, 196.6857, 141.3655]) Cost: 0.328031\n",
      "Epoch 6400/10000 hypothesis: tensor([151.5126, 184.5712, 180.5883, 196.6826, 141.3736]) Cost: 0.325184\n",
      "Epoch 6500/10000 hypothesis: tensor([151.5057, 184.5761, 180.5864, 196.6796, 141.3815]) Cost: 0.322456\n",
      "Epoch 6600/10000 hypothesis: tensor([151.4989, 184.5809, 180.5845, 196.6766, 141.3892]) Cost: 0.319850\n",
      "Epoch 6700/10000 hypothesis: tensor([151.4923, 184.5856, 180.5827, 196.6736, 141.3967]) Cost: 0.317358\n",
      "Epoch 6800/10000 hypothesis: tensor([151.4859, 184.5902, 180.5810, 196.6707, 141.4041]) Cost: 0.314968\n",
      "Epoch 6900/10000 hypothesis: tensor([151.4797, 184.5946, 180.5793, 196.6679, 141.4112]) Cost: 0.312674\n",
      "Epoch 7000/10000 hypothesis: tensor([151.4737, 184.5989, 180.5777, 196.6651, 141.4182]) Cost: 0.310470\n",
      "Epoch 7100/10000 hypothesis: tensor([151.4678, 184.6031, 180.5761, 196.6623, 141.4251]) Cost: 0.308364\n",
      "Epoch 7200/10000 hypothesis: tensor([151.4621, 184.6071, 180.5745, 196.6596, 141.4317]) Cost: 0.306343\n",
      "Epoch 7300/10000 hypothesis: tensor([151.4566, 184.6110, 180.5730, 196.6569, 141.4383]) Cost: 0.304399\n",
      "Epoch 7400/10000 hypothesis: tensor([151.4513, 184.6148, 180.5716, 196.6543, 141.4446]) Cost: 0.302527\n",
      "Epoch 7500/10000 hypothesis: tensor([151.4462, 184.6186, 180.5702, 196.6517, 141.4509]) Cost: 0.300724\n",
      "Epoch 7600/10000 hypothesis: tensor([151.4411, 184.6222, 180.5689, 196.6491, 141.4569]) Cost: 0.298999\n",
      "Epoch 7700/10000 hypothesis: tensor([151.4363, 184.6256, 180.5676, 196.6466, 141.4629]) Cost: 0.297339\n",
      "Epoch 7800/10000 hypothesis: tensor([151.4316, 184.6291, 180.5664, 196.6441, 141.4687]) Cost: 0.295735\n",
      "Epoch 7900/10000 hypothesis: tensor([151.4270, 184.6323, 180.5652, 196.6417, 141.4743]) Cost: 0.294202\n",
      "Epoch 8000/10000 hypothesis: tensor([151.4225, 184.6355, 180.5640, 196.6393, 141.4799]) Cost: 0.292715\n",
      "Epoch 8100/10000 hypothesis: tensor([151.4183, 184.6387, 180.5629, 196.6369, 141.4853]) Cost: 0.291271\n",
      "Epoch 8200/10000 hypothesis: tensor([151.4141, 184.6416, 180.5618, 196.6345, 141.4906]) Cost: 0.289891\n",
      "Epoch 8300/10000 hypothesis: tensor([151.4100, 184.6446, 180.5608, 196.6322, 141.4957]) Cost: 0.288548\n",
      "Epoch 8400/10000 hypothesis: tensor([151.4061, 184.6474, 180.5598, 196.6299, 141.5008]) Cost: 0.287267\n",
      "Epoch 8500/10000 hypothesis: tensor([151.4024, 184.6502, 180.5588, 196.6276, 141.5057]) Cost: 0.286005\n",
      "Epoch 8600/10000 hypothesis: tensor([151.3987, 184.6528, 180.5579, 196.6254, 141.5106]) Cost: 0.284807\n",
      "Epoch 8700/10000 hypothesis: tensor([151.3951, 184.6554, 180.5570, 196.6232, 141.5153]) Cost: 0.283641\n",
      "Epoch 8800/10000 hypothesis: tensor([151.3917, 184.6580, 180.5562, 196.6210, 141.5199]) Cost: 0.282510\n",
      "Epoch 8900/10000 hypothesis: tensor([151.3884, 184.6604, 180.5553, 196.6189, 141.5244]) Cost: 0.281410\n",
      "Epoch 9000/10000 hypothesis: tensor([151.3851, 184.6628, 180.5545, 196.6168, 141.5288]) Cost: 0.280350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9100/10000 hypothesis: tensor([151.3820, 184.6651, 180.5538, 196.6147, 141.5331]) Cost: 0.279314\n",
      "Epoch 9200/10000 hypothesis: tensor([151.3790, 184.6673, 180.5530, 196.6126, 141.5374]) Cost: 0.278312\n",
      "Epoch 9300/10000 hypothesis: tensor([151.3761, 184.6694, 180.5523, 196.6106, 141.5415]) Cost: 0.277338\n",
      "Epoch 9400/10000 hypothesis: tensor([151.3732, 184.6715, 180.5517, 196.6086, 141.5455]) Cost: 0.276395\n",
      "Epoch 9500/10000 hypothesis: tensor([151.3705, 184.6736, 180.5510, 196.6066, 141.5495]) Cost: 0.275476\n",
      "Epoch 9600/10000 hypothesis: tensor([151.3679, 184.6755, 180.5504, 196.6046, 141.5534]) Cost: 0.274577\n",
      "Epoch 9700/10000 hypothesis: tensor([151.3653, 184.6775, 180.5498, 196.6027, 141.5571]) Cost: 0.273705\n",
      "Epoch 9800/10000 hypothesis: tensor([151.3628, 184.6793, 180.5493, 196.6008, 141.5608]) Cost: 0.272862\n",
      "Epoch 9900/10000 hypothesis: tensor([151.3604, 184.6811, 180.5487, 196.5989, 141.5645]) Cost: 0.272031\n",
      "Epoch 10000/10000 hypothesis: tensor([151.3581, 184.6828, 180.5482, 196.5970, 141.5680]) Cost: 0.271224\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "x_train  =  torch.FloatTensor([[73,  80,  75], \n",
    "                               [93,  88,  93], \n",
    "                               [89,  91,  90], \n",
    "                               [96,  98,  100],   \n",
    "                               [73,  66,  70]])  \n",
    "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])\n",
    "\n",
    "# 모델 초기화\n",
    "W = torch.zeros((3, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD([W, b], lr=0.00001)\n",
    "\n",
    "nb_epochs = 10000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    # H(x) 계산\n",
    "    # 편향 b는 브로드 캐스팅되어 각 샘플에 더해집니다.\n",
    "    hypothesis = x_train.matmul(W) + b\n",
    "\n",
    "    # cost 계산\n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch%100 ==0:\n",
    "        # 100번마다 로그 출력\n",
    "        print('Epoch {:4d}/{} hypothesis: {} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, hypothesis.squeeze().detach(), cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
